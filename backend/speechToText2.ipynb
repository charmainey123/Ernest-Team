{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de00016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import soundfile as sf\n",
    "import openai\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7937506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading API Key\n",
    "with open(\"./apikey.txt\") as file:\n",
    "    openai.api_key = file.read()\n",
    "\n",
    "# Define path to audio output file\n",
    "output_audio_file = \"./output.mp3\"\n",
    "\n",
    "# Initializing text-to-speech object\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Define the persona of Ernest\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Ernest, a friendly and empathetic virtual avatar from Standard Chartered Bank that can help recommend one of the bank savings account or current account best suited to customers' needs through meaningful conversations. When customers are lost, he can also explain how to fill up the bank account application form.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e59255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def generate_response(transcript):\n",
    "    \n",
    "    transcript += '->'\n",
    "    # Append to the conversation\n",
    "    messages.append({\"role\": \"user\", \"content\": transcript})\n",
    "    conversation_context = ' '.join([f\"{msg['role']}: {msg['content']}\" for msg in messages])\n",
    "    \n",
    "    # Generate an instance of fine-tuned chatGPT\n",
    "    response = openai.Completion.create(engine='curie:ft-personal-2023-06-05-05-52-26',\n",
    "                                        prompt=conversation_context,\n",
    "                                        temperature=0.7,\n",
    "                                        max_tokens=50,\n",
    "                                        n=1,\n",
    "                                        stop=[\"\\n\"],\n",
    "                                        timeout=None).choices[0].text.strip()\n",
    "    print(\"Response generated from openai:\", response)\n",
    "    \n",
    "    if response == ' myway':\n",
    "        response = 'I would recommend you to get MyWay, a savings account meant for those above 55 years old and above to enjoy a world of exclusive dining, travel and healthcare privileges. You may enjoy interest rates of up to 0.30% per annum, access to income generating wealth solutions and enjoy privileges at selected merchants on travel and health.'\n",
    "    elif response == ' no product':\n",
    "        response = 'I would love to help you but unfortunately we do not have any bank accounts suitable for you at this moment. This could be due to various reasons, for instance, you may not have reached the minimum age for our bank accounts. We are constantly reviewing the needs of our dearest customrs like you. How about this? You may leave your contact details down and we could let you know if there are new product offerings that are suitable for you?'\n",
    "    elif response == ' e$aver':\n",
    "        response = 'I would recommend you to get the e$aver account, an online savings account that earns higher interest rate with flexibility of accessing your funds anytime. Based on what I hear, it seems you have some spare cash that you may need from time to time, yet is also looking for high interests. Our e$aver account is best for you! We have a special promotion right now, where you may earn up to 3.40% per annum in bonus interest rate and eligible incremental balance up to $2 million, with no lock in period at all.'\n",
    "    elif response == ' xtrasaver':\n",
    "        response = 'I would recommend you to get our XtraSaver, an interest bearing current account that allows you to earn cashback on your debit card purchases. We are not kidding! You can receive up to 3% cashback on your Mastercard transactions, anywhere in the world, and also up to 15% cashback on petrol on top of prevailing station discounts. I really recommend this to you based on what I have heard of your lifestyle habits and needs.'\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb3ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part of the code is triggered when the user clicks on the button \"speak to Ernest\"\n",
    "\"\"\"\n",
    "\n",
    "def trigger_response():\n",
    "    try:\n",
    "        with sr.Microphone() as mic:\n",
    "            recognizer = sr.Recognizer()\n",
    "            recognizer.adjust_for_ambient_noise(mic, duration = 1)\n",
    "\n",
    "            # Line 13 will be replaced by D-ID audio once it is ready to make the voice quality more consistent\n",
    "            speak(\"How can I help you?\")\n",
    "            audio = recognizer.listen(mic, phrase_time_limit=None, timeout=None)\n",
    "            with open(output_audio_file, \"wb\") as f:\n",
    "                f.write(audio.get_wav_data(convert_rate=44100, convert_width=2))\n",
    "            audio_file = open(output_audio_file, \"rb\")\n",
    "            transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)[\"text\"]\n",
    "            print(\"The transcript is:\", transcript)\n",
    "            response = generate_response(transcript)\n",
    "            print(\"The response is:\", response)\n",
    "\n",
    "            # Line 24 will be replaced by D-ID once it is ready\n",
    "            speak(response)\n",
    "    except sr.UnknownValueError:\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3913c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No audio detected. Continue detecting in background...\n",
      "hi ernest\n",
      "The transcript is: I'm under 18 years old. What do you have to recommend to me?\n",
      "Response generated from openai: assistant:  user: I'm under 18 years. What products do you have to recommend to me?\n",
      "The response is: assistant:  user: I'm under 18 years. What products do you have to recommend to me?\n",
      "No audio detected. Continue detecting in background...\n",
      "No audio detected. Continue detecting in background...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7a07c670d087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase_time_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    489\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m                     \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    568\u001b[0m                 raise IOError(\"Not input stream\",\n\u001b[0;32m    569\u001b[0m                               paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[1;33m             return pa.read_stream(self._stream, num_frames,\n\u001b[0m\u001b[0;32m    571\u001b[0m                                   exception_on_overflow)\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        with sr.Microphone() as mic:\n",
    "            recognizer = sr.Recognizer()\n",
    "            recognizer.adjust_for_ambient_noise(mic, duration = 0.3)\n",
    "            audio = recognizer.listen(mic, phrase_time_limit=3)\n",
    "            call = recognizer.recognize_google(audio).lower()\n",
    "            print(call)\n",
    "\n",
    "            if 'ernest' in call or 'honest' in call or 'hyannis' in call or 'earnest' in call:\n",
    "                trigger_response()\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"No audio detected. Continue detecting in background...\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
